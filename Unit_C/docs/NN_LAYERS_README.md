# ç¥ç»ç½‘ç»œåŸºç¡€å±‚ C å®ç°

## ğŸ“‹ é—®é¢˜

**nn.Linear, nn.Unfold, nn.PReLU å¯ä»¥ç”¨ C è¯­è¨€å®ç°å—ï¼Ÿ**

## âœ… ç­”æ¡ˆ

**æ˜¯çš„ï¼å®Œå…¨å¯ä»¥ï¼è€Œä¸”å®ç°ç®€å•é«˜æ•ˆï¼**

## ğŸ“¦ å·²å®ç°çš„å±‚

| PyTorch å±‚ | C å‡½æ•° | ç”¨é€” |
|-----------|--------|------|
| `nn.Linear` | `linear_forward()` | å…¨è¿æ¥å±‚ |
| `nn.Unfold` | `unfold_forward()` | å±•å¼€æ“ä½œï¼ˆim2colï¼‰ |
| `nn.PReLU` | `prelu_forward_v2()` | å‚æ•°åŒ– ReLU |
| `nn.Sigmoid` | `sigmoid_forward()` | Sigmoid æ¿€æ´» |
| `nn.Tanh` | `tanh_forward()` | Tanh æ¿€æ´» |

## ğŸ¯ GTCRN ä¸­çš„ä½¿ç”¨

### 1. nn.Unfold - SFE æ¨¡å—

```python
# gtcrn1.py lines 64-74
class SFE(nn.Module):
    """Subband Feature Extraction"""
    def __init__(self, kernel_size=3, stride=1):
        super().__init__()
        self.unfold = nn.Unfold(
            kernel_size=(1,kernel_size),
            stride=(1, stride),
            padding=(0, (kernel_size-1)//2)
        )
```

**ä½œç”¨**: æå–å­å¸¦ç‰¹å¾ï¼Œå°†é¢‘ç‡é‚»åŸŸå±•å¼€ä¸ºé€šé“

### 2. nn.Linear - TRA æ¨¡å—

```python
# gtcrn1.py lines 77-93
class TRA(nn.Module):
    """Temporal Recurrent Attention"""
    def __init__(self, channels):
        super().__init__()
        self.att_gru = nn.GRU(channels, channels*2, 1, batch_first=True)
        self.att_fc = nn.Linear(channels*2, channels)  # â† Linear
        self.att_act = nn.Sigmoid()
```

**ä½œç”¨**: æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„å…¨è¿æ¥å±‚

### 3. nn.PReLU - æ¿€æ´»å‡½æ•°

```python
# gtcrn1.py lines 102, 119, 125
self.act = nn.PReLU()  # ConvBlock
self.point_act = nn.PReLU()  # GTConvBlock
self.depth_act = nn.PReLU()  # GTConvBlock
```

**ä½œç”¨**: æ‰€æœ‰å·ç§¯å—çš„æ¿€æ´»å‡½æ•°

### 4. nn.Sigmoid - æ³¨æ„åŠ›æƒé‡

```python
# gtcrn1.py line 83
self.att_act = nn.Sigmoid()  # TRA
```

**ä½œç”¨**: ç”Ÿæˆ (0,1) èŒƒå›´çš„æ³¨æ„åŠ›æƒé‡

## ğŸ’» C å®ç°

### æ–‡ä»¶ç»“æ„

```
Unit_C/
â”œâ”€â”€ nn_layers.h              â† å¤´æ–‡ä»¶
â”œâ”€â”€ nn_layers.c              â† å®ç°
â”œâ”€â”€ test_nn_layers.c         â† æµ‹è¯•
â””â”€â”€ Makefile_nn_layers       â† ç¼–è¯‘é…ç½®
```

### 1. nn.Linear

#### å…¬å¼
```
y = x @ W^T + b
```

#### C å®ç°

```c
// åˆ›å»º Linear å‚æ•°
LinearParams* linear_params = linear_create(
    in_features,    // è¾“å…¥ç‰¹å¾æ•°
    out_features,   // è¾“å‡ºç‰¹å¾æ•°
    weight,         // æƒé‡ (out_features, in_features)
    bias,           // åç½® (out_features)
    use_bias        // æ˜¯å¦ä½¿ç”¨åç½®
);

// å‰å‘ä¼ æ’­
linear_forward(
    input,          // è¾“å…¥ (batch_size, in_features)
    output,         // è¾“å‡º (batch_size, out_features)
    batch_size,     // æ‰¹æ¬¡å¤§å°
    linear_params   // å‚æ•°
);

// æ¸…ç†
linear_free(linear_params);
```

#### ç¤ºä¾‹

```c
// TRA æ¨¡å—: Linear(channels*2, channels)
int in_features = 32;   // channels * 2
int out_features = 16;  // channels
int batch_size = 63;    // time_steps

LinearParams* linear = linear_create(
    in_features, out_features, weight, bias, 1
);

linear_forward(input, output, batch_size, linear);
```

### 2. nn.Unfold

#### å…¬å¼
```
å°† (B, C, H, W) å±•å¼€ä¸º (B, C*kh*kw, L)
å…¶ä¸­ L = output_h * output_w
```

#### C å®ç°

```c
// è®¾ç½® Unfold å‚æ•°
UnfoldParams unfold_params = {
    .kernel_h = 1,
    .kernel_w = 3,
    .stride_h = 1,
    .stride_w = 1,
    .padding_h = 0,
    .padding_w = 1,
    .dilation_h = 1,
    .dilation_w = 1
};

// å±•å¼€å¹¶ reshape ä¸º 4Dï¼ˆGTCRN SFE ä½¿ç”¨æ–¹å¼ï¼‰
unfold_reshape_4d(
    input,          // (B, C, T, F)
    output,         // (B, C*kernel_size, T, F)
    &unfold_params
);
```

#### ç¤ºä¾‹

```c
// SFE æ¨¡å—: Unfold(kernel_size=(1,3), stride=(1,1), padding=(0,1))
Tensor* input = tensor_create(1, 8, 63, 97);   // (B, C, T, F)
Tensor* output = tensor_create(1, 24, 63, 97); // (B, C*3, T, F)

UnfoldParams params = {
    .kernel_h = 1, .kernel_w = 3,
    .stride_h = 1, .stride_w = 1,
    .padding_h = 0, .padding_w = 1,
    .dilation_h = 1, .dilation_w = 1
};

unfold_reshape_4d(input, output, &params);
```

### 3. nn.PReLU

#### å…¬å¼
```
y = x           if x > 0
y = alpha * x   if x <= 0
```

#### C å®ç°

```c
// åˆ›å»º PReLU å‚æ•°
float prelu_weights[16];
for (int i = 0; i < 16; i++) {
    prelu_weights[i] = 0.25f;  // PyTorch é»˜è®¤å€¼
}

PReLUParams* prelu = prelu_create(
    num_channels,   // å‚æ•°æ•°é‡ï¼ˆé€šå¸¸ç­‰äºé€šé“æ•°ï¼‰
    prelu_weights   // æ¯ä¸ªé€šé“çš„è´Ÿæ–œç‡
);

// å‰å‘ä¼ æ’­ï¼ˆin-placeï¼‰
prelu_forward_v2(
    input,          // (B, C, H, W)
    prelu
);

// æ¸…ç†
prelu_free(prelu);
```

#### ç¤ºä¾‹

```c
// ConvBlock: PReLU()
Tensor* input = tensor_create(1, 16, 63, 97);

float weights[16];
for (int i = 0; i < 16; i++) {
    weights[i] = 0.25f;
}

PReLUParams* prelu = prelu_create(16, weights);
prelu_forward_v2(input, prelu);
```

### 4. nn.Sigmoid

#### å…¬å¼
```
y = 1 / (1 + exp(-x))
```

#### C å®ç°

```c
// æ–¹å¼ 1: ç›´æ¥æ“ä½œæ•°ç»„
sigmoid_forward(
    data,           // æ•°æ®æŒ‡é’ˆ
    size            // æ•°æ®å¤§å°
);

// æ–¹å¼ 2: æ“ä½œ Tensor
sigmoid_forward_tensor(
    input           // (B, C, H, W)
);
```

#### ç¤ºä¾‹

```c
// TRA æ¨¡å—: Sigmoid()
Tensor* attention = tensor_create(1, 16, 63, 1);

// è®¡ç®—æ³¨æ„åŠ›æƒé‡
sigmoid_forward_tensor(attention);

// ç°åœ¨ attention çš„å€¼åœ¨ (0, 1) èŒƒå›´å†…
```

## ğŸš€ ç¼–è¯‘å’Œè¿è¡Œ

### Windows

```batch
cd Unit_C
gcc -Wall -O2 -std=c99 -c conv2d.c
gcc -Wall -O2 -std=c99 -c nn_layers.c
gcc -Wall -O2 -std=c99 -c test_nn_layers.c
gcc conv2d.o nn_layers.o test_nn_layers.o -o test_nn_layers.exe -lm
test_nn_layers.exe
```

### Linux/Mac

```bash
cd Unit_C
make -f Makefile_nn_layers
./test_nn_layers
```

## ğŸ“Š æµ‹è¯•è¾“å‡º

ç¨‹åºè¿è¡Œ 6 ä¸ªæµ‹è¯•ï¼š

### Test 1: nn.Linear
æµ‹è¯•å…¨è¿æ¥å±‚çš„çŸ©é˜µä¹˜æ³•

### Test 2: nn.Unfold
æµ‹è¯•å±•å¼€æ“ä½œï¼ˆim2colï¼‰

### Test 3: nn.PReLU
æµ‹è¯•å‚æ•°åŒ– ReLU æ¿€æ´»

### Test 4: nn.Sigmoid
æµ‹è¯• Sigmoid æ¿€æ´»å‡½æ•°

### Test 5: GTCRN SFE æ¨¡å—
å®Œæ•´çš„ SFE æ¨¡å—å®ç°

### Test 6: GTCRN TRA æ³¨æ„åŠ›
TRA æ¨¡å—çš„ Linear + Sigmoid éƒ¨åˆ†

## ğŸ” å®ç°ç»†èŠ‚

### nn.Linear å®ç°

```c
void linear_forward(
    const float* input,
    float* output,
    int batch_size,
    const LinearParams* params
) {
    int in_features = params->in_features;
    int out_features = params->out_features;

    // å¯¹æ¯ä¸ªæ‰¹æ¬¡æ ·æœ¬
    for (int b = 0; b < batch_size; b++) {
        // å¯¹æ¯ä¸ªè¾“å‡ºç‰¹å¾
        for (int o = 0; o < out_features; o++) {
            float sum = 0.0f;

            // çŸ©é˜µä¹˜æ³•
            for (int i = 0; i < in_features; i++) {
                sum += input[b * in_features + i] *
                       params->weight[o * in_features + i];
            }

            // åŠ åç½®
            if (params->use_bias) {
                sum += params->bias[o];
            }

            output[b * out_features + o] = sum;
        }
    }
}
```

### nn.Unfold å®ç°ï¼ˆGTCRN ç‰¹åŒ–ç‰ˆæœ¬ï¼‰

```c
void unfold_reshape_4d(
    const Tensor* input,
    Tensor* output,
    const UnfoldParams* params
) {
    // å¯¹æ¯ä¸ªä½ç½®
    for (int h = 0; h < height; h++) {
        for (int w = 0; w < width; w++) {
            // å¯¹æ¯ä¸ªå·ç§¯æ ¸ä½ç½®
            for (int kh = 0; kh < kernel_h; kh++) {
                for (int kw = 0; kw < kernel_w; kw++) {
                    // è®¡ç®—è¾“å…¥ä½ç½®ï¼ˆè€ƒè™‘ paddingï¼‰
                    int ih = h * stride_h - padding_h + kh * dilation_h;
                    int iw = w * stride_w - padding_w + kw * dilation_w;

                    // è¯»å–å€¼ï¼ˆè¾¹ç•Œå¤–ä¸º 0ï¼‰
                    float val = 0.0f;
                    if (ih >= 0 && ih < in_h && iw >= 0 && iw < in_w) {
                        val = input->data[...];
                    }

                    // å†™å…¥è¾“å‡ºï¼ˆå±•å¼€ä¸ºæ–°é€šé“ï¼‰
                    int out_c = c * kernel_h * kernel_w + kh * kernel_w + kw;
                    output->data[...] = val;
                }
            }
        }
    }
}
```

### nn.PReLU å®ç°

```c
void prelu_forward_v2(
    Tensor* input,
    const PReLUParams* params
) {
    // å¯¹æ¯ä¸ªé€šé“
    for (int c = 0; c < channels; c++) {
        float alpha = params->weight[c];

        // å¯¹æ¯ä¸ªç©ºé—´ä½ç½®
        for (int h = 0; h < height; h++) {
            for (int w = 0; w < width; w++) {
                int idx = ((b * channels + c) * height + h) * width + w;

                // PReLU
                if (input->data[idx] < 0) {
                    input->data[idx] *= alpha;
                }
            }
        }
    }
}
```

## ğŸ“ˆ æ€§èƒ½ç‰¹ç‚¹

### nn.Linear
- **å¤æ‚åº¦**: O(batch_size Ã— in_features Ã— out_features)
- **ä¼˜åŒ–**: å¯ä½¿ç”¨ BLAS åº“åŠ é€ŸçŸ©é˜µä¹˜æ³•

### nn.Unfold
- **å¤æ‚åº¦**: O(B Ã— C Ã— H Ã— W Ã— kh Ã— kw)
- **å†…å­˜**: è¾“å‡ºå¤§å° = è¾“å…¥å¤§å° Ã— kernel_size
- **ä¼˜åŒ–**: å¯å¹¶è¡ŒåŒ–

### nn.PReLU
- **å¤æ‚åº¦**: O(B Ã— C Ã— H Ã— W)
- **å†…å­˜**: In-place æ“ä½œï¼Œæ— é¢å¤–å†…å­˜
- **ä¼˜åŒ–**: å¯ SIMD å‘é‡åŒ–

### nn.Sigmoid
- **å¤æ‚åº¦**: O(size)
- **å†…å­˜**: In-place æ“ä½œ
- **ä¼˜åŒ–**: å¯ä½¿ç”¨æŸ¥æ‰¾è¡¨æˆ–å¿«é€Ÿè¿‘ä¼¼

## ğŸ“ GTCRN æ¨¡å—å¯¹åº”

### SFE (Subband Feature Extraction)

```c
// gtcrn1.py lines 64-74
// Input: (B, C, T, F)
// Output: (B, C*3, T, F)

UnfoldParams sfe_params = {
    .kernel_h = 1, .kernel_w = 3,
    .stride_h = 1, .stride_w = 1,
    .padding_h = 0, .padding_w = 1,
    .dilation_h = 1, .dilation_w = 1
};

unfold_reshape_4d(input, output, &sfe_params);
```

### TRA (Temporal Recurrent Attention)

```c
// gtcrn1.py lines 77-93
// 1. GRU (éœ€è¦å•ç‹¬å®ç°)
// 2. Linear
LinearParams* tra_linear = linear_create(
    channels * 2, channels, weight, bias, 1
);
linear_forward(gru_output, linear_output, batch * time_steps, tra_linear);

// 3. Sigmoid
sigmoid_forward(linear_output, batch * time_steps * channels);

// 4. åº”ç”¨æ³¨æ„åŠ›
// output = input * attention_weights
```

### ConvBlock

```c
// gtcrn1.py lines 96-104
// Conv2d + BatchNorm2d + PReLU

// 1. Conv2d (æˆ– ConvTranspose2d)
conv2d_forward(input, output, &conv_params);

// 2. BatchNorm2d
batchnorm2d_forward(output, bn_params);

// 3. PReLU
prelu_forward_v2(output, prelu_params);
```

### GTConvBlock

```c
// gtcrn1.py lines 107-153
// SFE + Point Conv + Depth Conv + Point Conv + TRA

// 1. SFE
unfold_reshape_4d(x1, sfe_output, &sfe_params);

// 2. Point Conv + BN + PReLU
conv2d_forward(sfe_output, h1, &point_conv1_params);
batchnorm2d_forward(h1, bn1_params);
prelu_forward_v2(h1, prelu_params);

// 3. Depth Conv + BN + PReLU
conv2d_forward(h1, h2, &depth_conv_params);
batchnorm2d_forward(h2, bn2_params);
prelu_forward_v2(h2, prelu_params);

// 4. Point Conv + BN
conv2d_forward(h2, h3, &point_conv2_params);
batchnorm2d_forward(h3, bn3_params);

// 5. TRA (éœ€è¦ GRU + Linear + Sigmoid)
// ...
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### å†…å­˜ç®¡ç†
- Linear: éœ€è¦åˆ†é…è¾“å‡ºç¼“å†²åŒº
- Unfold: è¾“å‡ºå¤§å° = è¾“å…¥å¤§å° Ã— kernel_size
- PReLU: In-place æ“ä½œ
- Sigmoid: In-place æ“ä½œ

### æ•°å€¼ç¨³å®šæ€§
- Sigmoid: å¯¹äºå¤§çš„è´Ÿæ•°ï¼Œexp(-x) å¯èƒ½æº¢å‡º
  - è§£å†³: ä½¿ç”¨ `1 / (1 + exp(-x))` æˆ–æŸ¥æ‰¾è¡¨
- Linear: æƒé‡åˆå§‹åŒ–å¾ˆé‡è¦
  - å»ºè®®: Xavier æˆ– He åˆå§‹åŒ–

### æ€§èƒ½ä¼˜åŒ–
- Linear: ä½¿ç”¨ BLAS åº“ï¼ˆå¦‚ OpenBLASï¼‰
- Unfold: å¹¶è¡ŒåŒ–å¤–å±‚å¾ªç¯
- PReLU: SIMD å‘é‡åŒ–
- Sigmoid: æŸ¥æ‰¾è¡¨æˆ–å¤šé¡¹å¼è¿‘ä¼¼

## ğŸ“š ç›¸å…³æ–‡ä»¶

### å®ç°æ–‡ä»¶
- [nn_layers.h](nn_layers.h) - å¤´æ–‡ä»¶
- [nn_layers.c](nn_layers.c) - å®ç°
- [conv2d.h](conv2d.h) - Conv2d å¤´æ–‡ä»¶ï¼ˆä¾èµ–ï¼‰
- [conv2d.c](conv2d.c) - Conv2d å®ç°ï¼ˆä¾èµ–ï¼‰

### æµ‹è¯•æ–‡ä»¶
- [test_nn_layers.c](test_nn_layers.c) - å®Œæ•´æµ‹è¯•

### æ„å»ºæ–‡ä»¶
- [Makefile_nn_layers](Makefile_nn_layers) - ç¼–è¯‘é…ç½®

## âœ… æ€»ç»“

### é—®é¢˜
nn.Linear, nn.Unfold, nn.PReLU å¯ä»¥ç”¨ C è¯­è¨€å®ç°å—ï¼Ÿ

### ç­”æ¡ˆ
**æ˜¯çš„ï¼å®Œå…¨å¯ä»¥ï¼**

### å·²å®ç°
- âœ… nn.Linear - å…¨è¿æ¥å±‚
- âœ… nn.Unfold - å±•å¼€æ“ä½œ
- âœ… nn.PReLU - å‚æ•°åŒ– ReLU
- âœ… nn.Sigmoid - Sigmoid æ¿€æ´»
- âœ… nn.Tanh - Tanh æ¿€æ´»

### ç‰¹ç‚¹
- âœ… çº¯ C99 å®ç°
- âœ… æ— å¤–éƒ¨ä¾èµ–ï¼ˆä»… math.hï¼‰
- âœ… é«˜æ•ˆå®ç°
- âœ… æ˜“äºé›†æˆ
- âœ… å®Œæ•´æµ‹è¯•

### GTCRN åº”ç”¨
- SFE æ¨¡å—: Unfold
- TRA æ¨¡å—: Linear + Sigmoid
- ConvBlock: PReLU
- GTConvBlock: Unfold + PReLU

### ä½¿ç”¨
```bash
make -f Makefile_nn_layers run
```

---

**åˆ›å»ºæ—¶é—´**: 2025-12-18
**è¯­è¨€**: C99
**å¹³å°**: è·¨å¹³å°
**çŠ¶æ€**: âœ… å®Œæˆå¹¶æµ‹è¯•
