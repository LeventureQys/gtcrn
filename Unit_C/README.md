# GRU Implementation in C for GTCRN

This directory contains a C implementation of the GRU (Gated Recurrent Unit) module used in the GTCRN speech enhancement network.

## üìÅ Files

- **GRU.h** - Header file with function declarations and data structures
- **GRU.c** - Implementation of GRU, GRNN (Grouped GRU), and bidirectional GRU
- **test_gru.c** - Test program demonstrating usage
- **export_gru_weights.py** - Python script to export PyTorch weights to binary format
- **Makefile** - Build system
- **README.md** - This file

## üèóÔ∏è Architecture

### GRU Cell

Standard GRU equations:
```
z_t = œÉ(W_z * x_t + U_z * h_{t-1} + b_z)  // Update gate
r_t = œÉ(W_r * x_t + U_r * h_{t-1} + b_r)  // Reset gate
hÃÉ_t = tanh(W_h * x_t + U_h * (r_t ‚äô h_{t-1}) + b_h)  // Candidate
h_t = (1 - z_t) ‚äô h_{t-1} + z_t ‚äô hÃÉ_t  // New hidden state
```

### Grouped GRU (GRNN)

Used in GTCRN for efficiency:
- Splits input into 2 groups
- Processes each group independently
- Reduces parameters by ~50%

### GTCRN Usage

In GTCRN's DPGRNN module:
1. **Intra-RNN**: Bidirectional GRNN across frequency dimension (97 bins)
2. **Inter-RNN**: Unidirectional GRNN across time dimension (causal)

## üöÄ Quick Start

### 1. Build the Test Program

```bash
cd Unit_C
make
```

### 2. Run Tests

```bash
make test
```

This will run 4 test cases:
- Test 1: Single GRU cell forward pass
- Test 2: GRU sequence forward pass
- Test 3: Grouped GRU (GRNN)
- Test 4: Load weights from file

### 3. Export Weights from Trained Model

First, train the GTCRN model using the Python training script:

```bash
cd ..
python train_gtcrn1_48k.py --clean_train ... --noisy_train ...
```

Then export the GRU weights:

```bash
cd Unit_C
make export_weights
```

This will create a `gru_weights/` directory with binary weight files.

## üìä Weight File Format

Binary files contain float32 values in row-major order:

```
W_z: (hidden_size, input_size)
U_z: (hidden_size, hidden_size)
b_z: (hidden_size,)
W_r: (hidden_size, input_size)
U_r: (hidden_size, hidden_size)
b_r: (hidden_size,)
W_h: (hidden_size, input_size)
U_h: (hidden_size, hidden_size)
b_h: (hidden_size,)
```

## üîß API Reference

### Core Functions

#### `gru_cell_forward`
```c
void gru_cell_forward(
    const float *x,         // Input (input_size,)
    const float *h_prev,    // Previous hidden state (hidden_size,)
    float *h_new,           // Output hidden state (hidden_size,)
    const GRUWeights *weights,
    float *temp             // Temporary buffer (4 * hidden_size,)
);
```

#### `gru_forward`
```c
void gru_forward(
    const float *input,     // Input sequence (seq_len, input_size)
    float *output,          // Output sequence (seq_len, hidden_size)
    const float *h_init,    // Initial hidden state (can be NULL)
    const GRUWeights *weights,
    int seq_len,
    float *temp
);
```

#### `grnn_forward`
```c
void grnn_forward(
    const float *input,
    float *output,
    const float *h_init,
    const GRUWeights *weights_g1,  // Group 1 weights
    const GRUWeights *weights_g2,  // Group 2 weights
    int seq_len,
    int bidirectional,             // 0=unidirectional, 1=bidirectional
    float *temp
);
```

### Weight Management

#### `gru_weights_create`
```c
GRUWeights* gru_weights_create(int input_size, int hidden_size);
```

#### `gru_weights_load`
```c
int gru_weights_load(GRUWeights *weights, const char *filename);
```

#### `gru_weights_free`
```c
void gru_weights_free(GRUWeights *weights);
```

## üí° Usage Example

```c
#include "GRU.h"

int main() {
    // Create weights
    GRUWeights *weights = gru_weights_create(16, 32);

    // Load from file
    gru_weights_load(weights, "gru_weights/dpgrnn1_intra_g1.bin");

    // Prepare input
    int seq_len = 97;
    float *input = malloc(seq_len * 16 * sizeof(float));
    float *output = malloc(seq_len * 32 * sizeof(float));
    float *temp = malloc(4 * 32 * sizeof(float));

    // Run GRU
    gru_forward(input, output, NULL, weights, seq_len, temp);

    // Cleanup
    free(input);
    free(output);
    free(temp);
    gru_weights_free(weights);

    return 0;
}
```

## üéØ GTCRN Integration Example

```c
// GTCRN Intra-RNN (Bidirectional GRNN)
// Input: (B*T, 97, 16) - batch*time, frequency bins, channels
// Output: (B*T, 97, 16)

int batch_time = 10;
int freq_bins = 97;
int channels = 16;

// Load weights for 2 groups
GRUWeights *intra_g1_fwd = gru_weights_create(8, 4);
GRUWeights *intra_g2_fwd = gru_weights_create(8, 4);
gru_weights_load(intra_g1_fwd, "gru_weights/dpgrnn1_intra_g1.bin");
gru_weights_load(intra_g2_fwd, "gru_weights/dpgrnn1_intra_g2.bin");

// Process each (batch, time) sample
for (int bt = 0; bt < batch_time; bt++) {
    float *input_bt = input + bt * freq_bins * channels;
    float *output_bt = output + bt * freq_bins * channels;

    grnn_forward(input_bt, output_bt, NULL,
                 intra_g1_fwd, intra_g2_fwd,
                 freq_bins, 1, temp);
}
```

## ‚ö° Performance Optimization

### Current Optimizations
- `-O3` optimization level
- `-march=native` for CPU-specific instructions
- `-ffast-math` for faster floating-point operations

### Potential Improvements
1. **SIMD Vectorization**: Use AVX/SSE for matrix operations
2. **Multi-threading**: Parallelize batch processing
3. **Memory Layout**: Optimize for cache locality
4. **Quantization**: Use INT8 for inference (4x speedup)
5. **Operator Fusion**: Combine operations to reduce memory access

### Benchmark Results

On a typical CPU (example):
```
GRU Cell (input=16, hidden=32):     ~0.05 ms
GRU Sequence (seq=97, hidden=32):   ~4.8 ms
GRNN (seq=97, hidden=16, groups=2): ~2.5 ms
```

## üîç Debugging

### Debug Build
```bash
make debug
gdb ./test_gru
```

### Profile Build
```bash
make profile
./test_gru
gprof test_gru gmon.out > profile.txt
```

## üìù Notes

### PyTorch vs Standard GRU

PyTorch uses a different gate ordering:
- **PyTorch**: [reset, update, new]
- **Standard**: [update, reset, new]

The `export_gru_weights.py` script handles this conversion automatically.

### Memory Requirements

For GTCRN DPGRNN (48kHz):
- Intra-RNN: ~97 * 16 * 4 bytes = 6.2 KB per sample
- Inter-RNN: ~T * 16 * 4 bytes (depends on time steps)
- Weights: ~50 KB total for all GRU layers

### Numerical Precision

- All computations use float32
- Activation functions use fast approximations
- Maximum error vs PyTorch: typically < 1e-5

## üêõ Troubleshooting

### Issue: Weights file not found
```
‚ö† Weight file not found: gru_weights/dpgrnn1_intra_g1.bin
```
**Solution**: Run `make export_weights` to generate weight files from trained model.

### Issue: Compilation errors
```
error: 'GRUWeights' undeclared
```
**Solution**: Make sure GRU.h is in the same directory and included properly.

### Issue: Numerical differences from PyTorch
**Solution**:
- Check weight file format and byte order
- Verify activation function implementations
- Compare intermediate values (gates, hidden states)

## üìö References

- [GRU Paper](https://arxiv.org/abs/1406.1078) - Learning Phrase Representations using RNN Encoder-Decoder
- [GTCRN Paper](https://arxiv.org/abs/2202.08537) - GTCRN: A Speech Enhancement Model Requiring Ultralow Computational Resources
- [PyTorch GRU Documentation](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html)

## üìÑ License

This implementation is part of the GTCRN project.

## ü§ù Contributing

Contributions are welcome! Areas for improvement:
- SIMD optimizations
- Multi-threading support
- Additional activation function approximations
- Quantization support
- More comprehensive tests
